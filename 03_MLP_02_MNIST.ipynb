{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MigueXYLO/python/blob/main/03_MLP_02_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nwc9liPjQU0z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "S-jvKznSZYEc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BhikaXWXcWt",
        "outputId": "2e0dfb3d-0655-453b-b2b1-f358fc1235b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJVLe4TIXuBA",
        "outputId": "4a2fb48b-cf39-496a-f1c4-0283c4bcf972"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0sjBpkjXwmJ",
        "outputId": "9b4755e7-3bae-4468-c568-ec17877d2a72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit = train_images[4]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "XZI7qo30YDd-",
        "outputId": "0ad789ad-5794-4709-9111-1a8e5cb3486a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in digit:\n",
        "  for elem in row:\n",
        "    print(\"%3d\" % (elem), end=\" \")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOgXHGyCYJGZ",
        "outputId": "be591448-c533-433a-e85c-8426b7b5ce42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0  55 148 210 253 253 113  87 148  55   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0  87 232 252 253 189 210 252 252 253 168   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   4  57 242 252 190  65   5  12 182 252 253 116   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0  96 252 252 183  14   0   0  92 252 252 225  21   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0 132 253 252 146  14   0   0   0 215 252 252  79   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0 126 253 247 176   9   0   0   8  78 245 253 129   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0  16 232 252 176   0   0   0  36 201 252 252 169  11   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0  22 252 252  30  22 119 197 241 253 252 251  77   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0  16 231 252 253 252 252 252 226 227 252 231   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0  55 235 253 217 138  42  24 192 252 143   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0  62 255 253 109   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0  71 253 252  21   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0 253 252  21   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0  71 253 252  21   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0 106 253 252  21   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0  45 255 253  21   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0 218 252  56   0   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  96 252 189  42   0   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14 184 252 170  11   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14 147 252  42   0   0   0   0   0   0   0   0   0 \n",
            "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "85uWk4zfTnc1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HmDr-umGT99c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "metadata": {
        "id": "5XPx4vuZbJUe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "U5Pt0PBjbRjl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on the dataset\n",
        "model.fit(train_images, train_labels, epochs=150, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm13dJVDUEh6",
        "outputId": "40adafa2-16e8-4115-d317-2c377f03708d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 8.4487e-04 - accuracy: 0.9997\n",
            "Epoch 2/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 2.1609e-04 - accuracy: 1.0000\n",
            "Epoch 3/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.4505e-04 - accuracy: 0.9999\n",
            "Epoch 4/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 7.2372e-05 - accuracy: 1.0000\n",
            "Epoch 5/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.0888e-06 - accuracy: 1.0000\n",
            "Epoch 6/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.0687e-06 - accuracy: 1.0000\n",
            "Epoch 7/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.6945e-06 - accuracy: 1.0000\n",
            "Epoch 8/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 2.4397e-06 - accuracy: 1.0000\n",
            "Epoch 9/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 2.2460e-06 - accuracy: 1.0000\n",
            "Epoch 10/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.0861e-06 - accuracy: 1.0000\n",
            "Epoch 11/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.9558e-06 - accuracy: 1.0000\n",
            "Epoch 12/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.8433e-06 - accuracy: 1.0000\n",
            "Epoch 13/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.7463e-06 - accuracy: 1.0000\n",
            "Epoch 14/150\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.6621e-06 - accuracy: 1.0000\n",
            "Epoch 15/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.5867e-06 - accuracy: 1.0000\n",
            "Epoch 16/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.5196e-06 - accuracy: 1.0000\n",
            "Epoch 17/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 1.4596e-06 - accuracy: 1.0000\n",
            "Epoch 18/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.4042e-06 - accuracy: 1.0000\n",
            "Epoch 19/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.3535e-06 - accuracy: 1.0000\n",
            "Epoch 20/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.3078e-06 - accuracy: 1.0000\n",
            "Epoch 21/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.2651e-06 - accuracy: 1.0000\n",
            "Epoch 22/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.2249e-06 - accuracy: 1.0000\n",
            "Epoch 23/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 1.1886e-06 - accuracy: 1.0000\n",
            "Epoch 24/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.1546e-06 - accuracy: 1.0000\n",
            "Epoch 25/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.1229e-06 - accuracy: 1.0000\n",
            "Epoch 26/150\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.0932e-06 - accuracy: 1.0000\n",
            "Epoch 27/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.0649e-06 - accuracy: 1.0000\n",
            "Epoch 28/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.0381e-06 - accuracy: 1.0000\n",
            "Epoch 29/150\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.0131e-06 - accuracy: 1.0000\n",
            "Epoch 30/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 9.8914e-07 - accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 9.6712e-07 - accuracy: 1.0000\n",
            "Epoch 32/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 9.4567e-07 - accuracy: 1.0000\n",
            "Epoch 33/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 9.2530e-07 - accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 9.0622e-07 - accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 8.8783e-07 - accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 8.7010e-07 - accuracy: 1.0000\n",
            "Epoch 37/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 8.5348e-07 - accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 8.3731e-07 - accuracy: 1.0000\n",
            "Epoch 39/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 8.2152e-07 - accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 8.0727e-07 - accuracy: 1.0000\n",
            "Epoch 41/150\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 7.9313e-07 - accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 7.7957e-07 - accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 7.6636e-07 - accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 7.5371e-07 - accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 7.4167e-07 - accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 7.2995e-07 - accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 7.1872e-07 - accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 7.0775e-07 - accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 6.9739e-07 - accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 6.8719e-07 - accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 6.7726e-07 - accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 6.6772e-07 - accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 6.5850e-07 - accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 6.4952e-07 - accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 6.4085e-07 - accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 6.3229e-07 - accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 6.2432e-07 - accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 6.1623e-07 - accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 6.0857e-07 - accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 6.0104e-07 - accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.9372e-07 - accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 5.8648e-07 - accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.7954e-07 - accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 5.7272e-07 - accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 5.6615e-07 - accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 5.5972e-07 - accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.5347e-07 - accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 5.4726e-07 - accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 5.4141e-07 - accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.3545e-07 - accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.2983e-07 - accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.2424e-07 - accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.1872e-07 - accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 5.1343e-07 - accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 5.0820e-07 - accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 5.0313e-07 - accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.9804e-07 - accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.9323e-07 - accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.8839e-07 - accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.8377e-07 - accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.7916e-07 - accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.7474e-07 - accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 4.7028e-07 - accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.6596e-07 - accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 4.6174e-07 - accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.5764e-07 - accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 4.5351e-07 - accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.4951e-07 - accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.4557e-07 - accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.4180e-07 - accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.3800e-07 - accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 4.3437e-07 - accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 4.3073e-07 - accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 4.2719e-07 - accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.2359e-07 - accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 4.2010e-07 - accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.1672e-07 - accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.1346e-07 - accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 4.1015e-07 - accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 4.0688e-07 - accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 4.0375e-07 - accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 4.0066e-07 - accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.9762e-07 - accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.9457e-07 - accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.9165e-07 - accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.8868e-07 - accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.8576e-07 - accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.8293e-07 - accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.8015e-07 - accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.7747e-07 - accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 3.7479e-07 - accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.7216e-07 - accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 3.6950e-07 - accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.6694e-07 - accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.6444e-07 - accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.6189e-07 - accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.5943e-07 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.5698e-07 - accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.5461e-07 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.5223e-07 - accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.4993e-07 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.4758e-07 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.4525e-07 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.4310e-07 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.4089e-07 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.3866e-07 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.3661e-07 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.3445e-07 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.3236e-07 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.3030e-07 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.2818e-07 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.2623e-07 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.2423e-07 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.2217e-07 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.2031e-07 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 3.1837e-07 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.1644e-07 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.1460e-07 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.1285e-07 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.1093e-07 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.0916e-07 - accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 3.0742e-07 - accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 3.0560e-07 - accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 3.0387e-07 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 3.0217e-07 - accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 3.0048e-07 - accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.9874e-07 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 2.9712e-07 - accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 2.9549e-07 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 2.9383e-07 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce89a93dcc0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx5S9g2_bzek",
        "outputId": "9c66606d-8f77-4879-e8ba-3750ae66c452"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1061 - accuracy: 0.9863\n",
            "test_acc: 0.986299991607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj4SW0-uVZ3G",
        "outputId": "150e00ba-9ece-451e-b424-801ea9a97735"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/models/MNIST_MLP.h5')\n"
      ],
      "metadata": {
        "id": "LtLQgqPHVzjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d11b70-c30f-45cd-ba76-0871d30f0085"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}